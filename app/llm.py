import os
import json
import logging
from typing import Dict, Any
from pathlib import Path

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env —Ñ–∞–π–ª–∞
try:
    from dotenv import load_dotenv
    # –ò—â–µ–º .env —Ñ–∞–π–ª –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞
    env_path = Path(__file__).parent.parent / '.env'
    load_dotenv(dotenv_path=env_path)
    logger = logging.getLogger(__name__)
    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ {env_path}")
except ImportError:
    logger = logging.getLogger(__name__)
    logger.warning("python-dotenv –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")

try:
    import google.generativeai as genai
except Exception as e:
    genai = None

_API_KEY = os.environ.get("GEMINI_API_KEY")
_MODEL = None

def _init_model() -> None:
    global _MODEL
    if _MODEL is not None:
        return

    if genai is None:
        logger.warning("google-generativeai –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω; LLM-—Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        return

    if not _API_KEY:
        logger.warning("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è GEMINI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω–∞; LLM-—Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        return

    try:
        genai.configure(api_key=_API_KEY)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ .env –∏–ª–∏ –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ
        model_name = os.environ.get("GEMINI_MODEL", "gemini-2.0-flash-exp")
        _MODEL = genai.GenerativeModel(model_name)
        logger.info(f"Gemini –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ ({model_name})")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini: {e}")
        _MODEL = None


def llm_available() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ LLM."""
    _init_model()
    return _MODEL is not None


def explain_transaction(transaction: Dict[str, Any], result: Dict[str, Any]) -> str:
    """
    –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.

    Args:
        transaction: –≤—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (V1..V28, Amount, –æ–ø—Ü. Time)
        result: —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ –º–æ–¥–µ–ª–∏ (fraud_score, is_fraud, confidence, risk_level, threshold, model_info)

    Returns:
        str: –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
    """
    if not llm_available():
        return "LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ google-generativeai –∏ –∑–∞–¥–∞–π—Ç–µ GEMINI_API_KEY –≤ .env —Ñ–∞–π–ª–µ."

    try:
        score = result.get("fraud_score", 0)
        is_fraud = result.get("is_fraud", False)
        confidence = result.get("confidence", 0)
        risk_level = result.get("risk_level", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
        threshold = result.get("threshold", 0.5)
        model_info = result.get("model_info", {})
        amount = transaction.get("Amount", 0)

        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑ .env
        temperature = float(os.environ.get("GEMINI_TEMPERATURE", "0.3"))
        max_tokens = int(os.environ.get("GEMINI_MAX_TOKENS", "500"))

        prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º—É –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤—É. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏ –æ–±—ä—è—Å–Ω–∏ —Ä–µ—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

–î–ê–ù–ù–´–ï –¢–†–ê–ù–ó–ê–ö–¶–ò–ò:
‚Ä¢ –°—É–º–º–∞: {amount:.2f}
‚Ä¢ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {score:.4f} ({score*100:.2f}%)
‚Ä¢ –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {threshold}
‚Ä¢ –ò—Ç–æ–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ: {'üö® –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–û' if is_fraud else '‚úÖ –õ–ï–ì–ò–¢–ò–ú–ù–ê–Ø –¢–†–ê–ù–ó–ê–ö–¶–ò–Ø'}
‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {risk_level}
‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {confidence:.4f} ({confidence*100:.2f}%)
‚Ä¢ –ú–æ–¥–µ–ª—å: {model_info.get('model_name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')} (AUC: {model_info.get('model_auc', 'N/A')})

–ü–†–ò–ó–ù–ê–ö–ò –¢–†–ê–ù–ó–ê–ö–¶–ò–ò (PCA-–ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ):
{json.dumps({k: round(v, 4) if isinstance(v, (int, float)) else v for k, v in transaction.items()}, ensure_ascii=False, indent=2)}

–ó–ê–î–ê–ß–ê:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏ –¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:

**üîç –ê–ù–ê–õ–ò–ó –†–ò–°–ö–ê:**
- –û–ø–∏—à–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ V1-V28 –∏ —Å—É–º–º—ã
- –û–±—ä—è—Å–Ω–∏, –∫–∞–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —É–∫–∞–∑—ã–≤–∞—é—Ç –Ω–∞ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ –∏–ª–∏ –∏—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ
- –£–∫–∞–∂–∏ –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è

**üìä –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –ú–û–î–ï–õ–ò:**
- –û–±—ä—è—Å–Ω–∏, –ø–æ—á–µ–º—É –º–æ–¥–µ–ª—å –ø—Ä–∏–Ω—è–ª–∞ —Ç–∞–∫–æ–µ —Ä–µ—à–µ–Ω–∏–µ
- –ù–∞—Å–∫–æ–ª—å–∫–æ –±–ª–∏–∑–∫–æ –∑–Ω–∞—á–µ–Ω–∏–µ –∫ –ø–æ—Ä–æ–≥–æ–≤–æ–º—É
- –û—Ü–µ–Ω–∏ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

**‚ö° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:**
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –¥–∞–Ω–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –ú–µ—Ä—ã –ø—Ä–µ–¥–æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç–∏

–ü–∏—à–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω–æ. –ò–∑–±–µ–≥–∞–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –≤—ã–≤–æ–¥–∞—Ö."""

        generation_config = genai.types.GenerationConfig(
            temperature=temperature,
            max_output_tokens=max_tokens,
        )

        resp = _MODEL.generate_content(prompt, generation_config=generation_config)
        return (resp.text or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.").strip()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
        return f"–û—à–∏–±–∫–∞ LLM –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {str(e)}"