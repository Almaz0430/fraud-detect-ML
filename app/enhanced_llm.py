"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ AI-–æ–±—ä—è—Å–Ω–µ–Ω–∏–π —Å –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π.

–í–∫–ª—é—á–∞–µ—Ç:
- –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Gemini —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤
- –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ (—Ä—É—Å—Å–∫–∏–π, –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, –∫–∞–∑–∞—Ö—Å–∫–∏–π)
- –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Å–Ω–∏–∂–µ–Ω–∏—é —Ä–∏—Å–∫–æ–≤
"""

import os
import json
import logging
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler

logger = logging.getLogger(__name__)

try:
    import google.generativeai as genai
except Exception as e:
    genai = None

# –Ø–∑—ã–∫–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
SUPPORTED_LANGUAGES = {
    'ru': '—Ä—É—Å—Å–∫–∏–π',
    'en': 'english', 
    'kk': '“õ–∞–∑–∞“õ—à–∞'
}

# –ü—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
LANGUAGE_PROMPTS = {
    'ru': {
        'system': "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ –ø–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–º—É –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤—É. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏ –æ–±—ä—è—Å–Ω—è–π —Ä–µ—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
        'analysis_header': "üîç –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–†–ê–ù–ó–ê–ö–¶–ò–ò",
        'risk_factors': "üìä –§–ê–ö–¢–û–†–´ –†–ò–°–ö–ê",
        'similar_cases': "üîÑ –ü–û–•–û–ñ–ò–ï –°–õ–£–ß–ê–ò",
        'anomaly_analysis': "‚ö†Ô∏è –ê–ù–ê–õ–ò–ó –ê–ù–û–ú–ê–õ–ò–ô",
        'recommendations': "üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò",
        'model_interpretation': "ü§ñ –ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –ú–û–î–ï–õ–ò"
    },
    'en': {
        'system': "You are a financial fraud detection expert analyst. Analyze transactions and explain machine learning model decisions in English.",
        'analysis_header': "üîç DETAILED TRANSACTION ANALYSIS",
        'risk_factors': "üìä RISK FACTORS",
        'similar_cases': "üîÑ SIMILAR CASES",
        'anomaly_analysis': "‚ö†Ô∏è ANOMALY ANALYSIS", 
        'recommendations': "üí° RECOMMENDATIONS",
        'model_interpretation': "ü§ñ MODEL INTERPRETATION"
    },
    'kk': {
        'system': "–°—ñ–∑ “õ–∞—Ä–∂—ã–ª—ã“õ –∞–ª–∞—è“õ—Ç—ã“õ—Ç—ã –∞–Ω—ã“õ—Ç–∞—É –±–æ–π—ã–Ω—à–∞ —Å–∞—Ä–∞–ø—à—ã-—Ç–∞–ª–¥–∞—É—à—ã—Å—ã–∑. –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–ª–∞—Ä–¥—ã —Ç–∞–ª–¥–∞“£—ã–∑ –∂”ô–Ω–µ –º–∞—à–∏–Ω–∞–ª—ã“õ –æ“õ—ã—Ç—É –º–æ–¥–µ–ª—ñ–Ω—ñ“£ —à–µ—à—ñ–º–¥–µ—Ä—ñ–Ω “õ–∞–∑–∞“õ —Ç—ñ–ª—ñ–Ω–¥–µ —Ç“Ø—Å—ñ–Ω–¥—ñ—Ä—ñ“£—ñ–∑.",
        'analysis_header': "üîç –¢–†–ê–ù–ó–ê–ö–¶–ò–Ø–ù–´“¢ –¢–û–õ–´“ö –¢–ê–õ–î–ê–£–´",
        'risk_factors': "üìä –¢”ò–£–ï–ö–ï–õ –§–ê–ö–¢–û–†–õ–ê–†–´",
        'similar_cases': "üîÑ “∞“ö–°–ê–° –ñ–ê“í–î–ê–ô–õ–ê–†",
        'anomaly_analysis': "‚ö†Ô∏è –ê–ù–û–ú–ê–õ–ò–Ø –¢–ê–õ–î–ê–£–´",
        'recommendations': "üí° “∞–°–´–ù–´–°–¢–ê–†",
        'model_interpretation': "ü§ñ –ú–û–î–ï–õ–¨ –¢“Æ–°–Ü–ù–î–Ü–†–ú–ï–°–Ü"
    }
}

class EnhancedFraudExplainer:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞."""
    
    def __init__(self):
        self.model = None
        self.similar_cases_db = []
        self.anomaly_patterns = {}
        self._init_model()
        self._load_historical_cases()
    
    def _init_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini –º–æ–¥–µ–ª–∏."""
        api_key = os.environ.get("GEMINI_API_KEY")
        if not api_key or genai is None:
            logger.warning("Gemini API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return
        
        try:
            genai.configure(api_key=api_key)
            model_name = os.environ.get("GEMINI_MODEL", "gemini-2.0-flash-exp")
            self.model = genai.GenerativeModel(model_name)
            logger.info(f"Enhanced Gemini –º–æ–¥–µ–ª—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ ({model_name})")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Gemini: {e}")
    
    def _load_historical_cases(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö."""
        try:
            cases_file = Path("data/historical_cases.json")
            if cases_file.exists():
                with open(cases_file, 'r', encoding='utf-8') as f:
                    self.similar_cases_db = json.load(f)
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.similar_cases_db)} –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤")
            else:
                # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã
                self._create_sample_cases()
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤: {e}")
            self._create_sample_cases()
    
    def _create_sample_cases(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤."""
        self.similar_cases_db = [
            {
                "id": "case_001",
                "transaction": {"Amount": 1500.0, "V1": -2.1, "V2": 1.8, "V3": -1.2},
                "is_fraud": True,
                "description": "–ö—Ä—É–ø–Ω–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –≤ –Ω–µ—Ä–∞–±–æ—á–µ–µ –≤—Ä–µ–º—è —Å –∞–Ω–æ–º–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏",
                "pattern_type": "large_amount_anomaly",
                "risk_score": 0.95
            },
            {
                "id": "case_002", 
                "transaction": {"Amount": 50.0, "V1": 0.1, "V2": -0.2, "V3": 0.3},
                "is_fraud": False,
                "description": "–û–±—ã—á–Ω–∞—è –Ω–µ–±–æ–ª—å—à–∞—è –ø–æ–∫—É–ø–∫–∞ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏",
                "pattern_type": "normal_purchase",
                "risk_score": 0.05
            }
        ]
    
    def find_similar_cases(self, transaction: Dict[str, Any], top_k: int = 3) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Å–ª—É—á–∞–µ–≤."""
        if not self.similar_cases_db:
            return []
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            current_features = self._extract_features(transaction)
            similarities = []
            
            for case in self.similar_cases_db:
                case_features = self._extract_features(case["transaction"])
                similarity = self._calculate_similarity(current_features, case_features)
                similarities.append((similarity, case))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–∂–µ—Å—Ç–∏
            similarities.sort(key=lambda x: x[0], reverse=True)
            
            return [case for _, case in similarities[:top_k]]
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤: {e}")
            return []
    
    def _extract_features(self, transaction: Dict[str, Any]) -> np.ndarray:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏."""
        features = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º Amount
        features.append(transaction.get("Amount", 0))
        
        # –î–æ–±–∞–≤–ª—è–µ–º V1-V28
        for i in range(1, 29):
            features.append(transaction.get(f"V{i}", 0))
        
        return np.array(features).reshape(1, -1)
    
    def _calculate_similarity(self, features1: np.ndarray, features2: np.ndarray) -> float:
        """–†–∞—Å—á–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏."""
        try:
            return cosine_similarity(features1, features2)[0][0]
        except:
            return 0.0
    
    def analyze_anomalies(self, transaction: Dict[str, Any], result: Dict[str, Any]) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤."""
        anomalies = {
            "detected_anomalies": [],
            "severity_level": "low",
            "anomaly_score": 0.0,
            "pattern_types": []
        }
        
        try:
            amount = transaction.get("Amount", 0)
            fraud_score = result.get("fraud_score", 0)
            
            # –ê–Ω–∞–ª–∏–∑ —Å—É–º–º—ã
            if amount > 5000:
                anomalies["detected_anomalies"].append({
                    "type": "high_amount",
                    "description": f"–ù–µ–æ–±—ã—á–Ω–æ –≤—ã—Å–æ–∫–∞—è —Å—É–º–º–∞: {amount}",
                    "severity": "high"
                })
                anomalies["pattern_types"].append("large_transaction")
            
            if amount < 1:
                anomalies["detected_anomalies"].append({
                    "type": "micro_transaction", 
                    "description": f"–ú–∏–∫—Ä–æ—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è: {amount}",
                    "severity": "medium"
                })
                anomalies["pattern_types"].append("micro_payment")
            
            # –ê–Ω–∞–ª–∏–∑ PCA –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            extreme_features = []
            for i in range(1, 29):
                v_val = transaction.get(f"V{i}", 0)
                if abs(v_val) > 3:  # –ó–Ω–∞—á–µ–Ω–∏—è –∑–∞ –ø—Ä–µ–¥–µ–ª–∞–º–∏ 3 —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π
                    extreme_features.append(f"V{i}")
            
            if extreme_features:
                anomalies["detected_anomalies"].append({
                    "type": "extreme_features",
                    "description": f"–≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {', '.join(extreme_features)}",
                    "severity": "high" if len(extreme_features) > 5 else "medium"
                })
                anomalies["pattern_types"].append("feature_anomaly")
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–µ–≥–æ —É—Ä–æ–≤–Ω—è —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏
            high_severity_count = sum(1 for a in anomalies["detected_anomalies"] if a["severity"] == "high")
            if high_severity_count > 0:
                anomalies["severity_level"] = "high"
                anomalies["anomaly_score"] = min(0.9, fraud_score + 0.2)
            elif len(anomalies["detected_anomalies"]) > 0:
                anomalies["severity_level"] = "medium"
                anomalies["anomaly_score"] = fraud_score
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω–æ–º–∞–ª–∏–π: {e}")
        
        return anomalies
    
    def generate_recommendations(self, transaction: Dict[str, Any], result: Dict[str, Any], 
                               anomalies: Dict[str, Any], language: str = 'ru') -> List[Dict[str, str]]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å–Ω–∏–∂–µ–Ω–∏—é —Ä–∏—Å–∫–æ–≤."""
        recommendations = []
        
        try:
            fraud_score = result.get("fraud_score", 0)
            is_fraud = result.get("is_fraud", False)
            amount = transaction.get("Amount", 0)
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
            if is_fraud:
                if language == 'ru':
                    recommendations.extend([
                        {"type": "immediate", "action": "–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é"},
                        {"type": "investigation", "action": "–ü—Ä–æ–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ"},
                        {"type": "contact", "action": "–°–≤—è–∑–∞—Ç—å—Å—è —Å –∫–ª–∏–µ–Ω—Ç–æ–º –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"}
                    ])
                elif language == 'en':
                    recommendations.extend([
                        {"type": "immediate", "action": "Immediately block the transaction"},
                        {"type": "investigation", "action": "Conduct detailed investigation"},
                        {"type": "contact", "action": "Contact customer for verification"}
                    ])
                elif language == 'kk':
                    recommendations.extend([
                        {"type": "immediate", "action": "–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–Ω—ã –¥–µ—Ä–µ—É –±–ª–æ–∫—Ç–∞—É"},
                        {"type": "investigation", "action": "–¢–æ–ª—ã“õ —Ç–µ—Ä–≥–µ—É –∂“Ø—Ä–≥—ñ–∑—É"},
                        {"type": "contact", "action": "–†–∞—Å—Ç–∞—É “Ø—à—ñ–Ω –∫–ª–∏–µ–Ω—Ç–ø–µ–Ω –±–∞–π–ª–∞–Ω—ã—Å—É"}
                    ])
            
            elif fraud_score > 0.3:
                if language == 'ru':
                    recommendations.extend([
                        {"type": "monitoring", "action": "–£—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫–ª–∏–µ–Ω—Ç–∞"},
                        {"type": "verification", "action": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è"},
                        {"type": "limits", "action": "–í—Ä–µ–º–µ–Ω–Ω–æ —Å–Ω–∏–∑–∏—Ç—å –ª–∏–º–∏—Ç—ã"}
                    ])
                elif language == 'en':
                    recommendations.extend([
                        {"type": "monitoring", "action": "Enhance customer monitoring"},
                        {"type": "verification", "action": "Additional verification required"},
                        {"type": "limits", "action": "Temporarily reduce limits"}
                    ])
                elif language == 'kk':
                    recommendations.extend([
                        {"type": "monitoring", "action": "–ö–ª–∏–µ–Ω—Ç—Ç—ñ –∫“Ø—à–µ–π—Ç—ñ–ª–≥–µ–Ω –±–∞“õ—ã–ª–∞—É"},
                        {"type": "verification", "action": "“ö–æ—Å—ã–º—à–∞ —Ä–∞—Å—Ç–∞—É “õ–∞–∂–µ—Ç"},
                        {"type": "limits", "action": "–£–∞“õ—ã—Ç—à–∞ –ª–∏–º–∏—Ç—Ç–µ—Ä–¥—ñ —Ç”©–º–µ–Ω–¥–µ—Ç—É"}
                    ])
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–æ–º–∞–ª–∏–π
            for anomaly in anomalies.get("detected_anomalies", []):
                if anomaly["type"] == "high_amount":
                    if language == 'ru':
                        recommendations.append({
                            "type": "amount_check", 
                            "action": f"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –∫—Ä—É–ø–Ω–æ–π —Å—É–º–º—ã ({amount})"
                        })
                    elif language == 'en':
                        recommendations.append({
                            "type": "amount_check",
                            "action": f"Verify source of large amount ({amount})"
                        })
                    elif language == 'kk':
                        recommendations.append({
                            "type": "amount_check",
                            "action": f"“Æ–ª–∫–µ–Ω —Å–æ–º–º–∞–Ω—ã“£ –∫”©–∑—ñ–Ω —Ç–µ–∫—Å–µ—Ä—É ({amount})"
                        })
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {e}")
        
        return recommendations
    
    def generate_enhanced_explanation(self, transaction: Dict[str, Any], result: Dict[str, Any], 
                                    language: str = 'ru') -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏."""
        if not self.model:
            return "LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ google-generativeai –∏ –∑–∞–¥–∞–π—Ç–µ GEMINI_API_KEY"
        
        try:
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤
            similar_cases = self.find_similar_cases(transaction)
            
            # –ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π
            anomalies = self.analyze_anomalies(transaction, result)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendations = self.generate_recommendations(transaction, result, anomalies, language)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
            score = result.get("fraud_score", 0)
            is_fraud = result.get("is_fraud", False)
            confidence = result.get("confidence", 0)
            risk_level = result.get("risk_level", "unknown")
            threshold = result.get("threshold", 0.5)
            amount = transaction.get("Amount", 0)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è —è–∑—ã–∫–∞
            prompts = LANGUAGE_PROMPTS.get(language, LANGUAGE_PROMPTS['ru'])
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞
            prompt = f"""{prompts['system']}

{prompts['analysis_header']}:
‚Ä¢ –°—É–º–º–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {amount:.2f}
‚Ä¢ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {score:.4f} ({score*100:.2f}%)
‚Ä¢ –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {threshold}
‚Ä¢ –†–µ—à–µ–Ω–∏–µ: {'üö® –ú–û–®–ï–ù–ù–ò–ß–ï–°–¢–í–û' if is_fraud else '‚úÖ –õ–ï–ì–ò–¢–ò–ú–ù–ê–Ø'}
‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {risk_level}
‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.4f}

{prompts['risk_factors']}:
{json.dumps({k: round(v, 4) if isinstance(v, (int, float)) else v for k, v in transaction.items()}, ensure_ascii=False, indent=2)}

{prompts['similar_cases']}:
{json.dumps([{
    '–æ–ø–∏—Å–∞–Ω–∏–µ': case.get('description', ''),
    '—Ç–∏–ø_–ø–∞—Ç—Ç–µ—Ä–Ω–∞': case.get('pattern_type', ''),
    '—Ä–∏—Å–∫_—Å–∫–æ—Ä': case.get('risk_score', 0),
    '–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ': case.get('is_fraud', False)
} for case in similar_cases], ensure_ascii=False, indent=2)}

{prompts['anomaly_analysis']}:
–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –∞–Ω–æ–º–∞–ª–∏–∏: {len(anomalies.get('detected_anomalies', []))}
–£—Ä–æ–≤–µ–Ω—å —Å–µ—Ä—å–µ–∑–Ω–æ—Å—Ç–∏: {anomalies.get('severity_level', 'low')}
–¢–∏–ø—ã –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {', '.join(anomalies.get('pattern_types', []))}

{prompts['recommendations']}:
{json.dumps([{'—Ç–∏–ø': r['type'], '–¥–µ–π—Å—Ç–≤–∏–µ': r['action']} for r in recommendations], ensure_ascii=False, indent=2)}

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏ –¥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ —è–∑—ã–∫–µ {SUPPORTED_LANGUAGES[language]}. 

–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç–≤–µ—Ç–∞:
**{prompts['risk_factors']}**
- –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ —Ä–∏—Å–∫–∞
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–∏–º—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏

**{prompts['similar_cases']}**
- –ê–Ω–∞–ª–∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–æ—Ö–æ–∂–∏—Ö —Å–ª—É—á–∞–µ–≤
- –í—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è

**{prompts['anomaly_analysis']}**
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π
- –°—Ç–µ–ø–µ–Ω—å –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –Ω–æ—Ä–º—ã
- –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã

**{prompts['model_interpretation']}**
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
- –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è–Ω–∏—è
- –ù–∞–¥–µ–∂–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è

**{prompts['recommendations']}**
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
- –ü—Ä–µ–≤–µ–Ω—Ç–∏–≤–Ω—ã–µ –º–µ—Ä—ã
- –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–ü–∏—à–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏."""

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            generation_config = genai.types.GenerationConfig(
                temperature=float(os.environ.get("GEMINI_TEMPERATURE", "0.3")),
                max_output_tokens=int(os.environ.get("GEMINI_MAX_TOKENS", "1000")),
            )
            
            response = self.model.generate_content(prompt, generation_config=generation_config)
            return response.text.strip() if response.text else "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {e}")
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è: {str(e)}"
    
    def save_case_to_history(self, transaction: Dict[str, Any], result: Dict[str, Any], 
                           feedback: Optional[bool] = None):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–ª—É—á–∞—è –≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –±–∞–∑—É –¥–ª—è –æ–±—É—á–µ–Ω–∏—è."""
        try:
            case = {
                "id": f"case_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "timestamp": datetime.now().isoformat(),
                "transaction": transaction,
                "prediction": result,
                "feedback": feedback,
                "is_fraud": result.get("is_fraud", False),
                "risk_score": result.get("fraud_score", 0),
                "pattern_type": "auto_detected"
            }
            
            self.similar_cases_db.append(case)
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã
            if len(self.similar_cases_db) > 1000:
                self.similar_cases_db = self.similar_cases_db[-1000:]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
            os.makedirs("data", exist_ok=True)
            with open("data/historical_cases.json", 'w', encoding='utf-8') as f:
                json.dump(self.similar_cases_db, f, ensure_ascii=False, indent=2)
                
            logger.info(f"–°–ª—É—á–∞–π {case['id']} —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –±–∞–∑—É")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–ª—É—á–∞—è: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
enhanced_explainer = EnhancedFraudExplainer()

def get_enhanced_explanation(transaction: Dict[str, Any], result: Dict[str, Any], 
                           language: str = 'ru') -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è."""
    return enhanced_explainer.generate_enhanced_explanation(transaction, result, language)

def find_similar_transactions(transaction: Dict[str, Any], top_k: int = 3) -> List[Dict]:
    """–ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π."""
    return enhanced_explainer.find_similar_cases(transaction, top_k)

def analyze_transaction_anomalies(transaction: Dict[str, Any], result: Dict[str, Any]) -> Dict[str, Any]:
    """–ê–Ω–∞–ª–∏–∑ –∞–Ω–æ–º–∞–ª–∏–π –≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏."""
    return enhanced_explainer.analyze_anomalies(transaction, result)

def get_risk_recommendations(transaction: Dict[str, Any], result: Dict[str, Any], 
                           language: str = 'ru') -> List[Dict[str, str]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å–Ω–∏–∂–µ–Ω–∏—é —Ä–∏—Å–∫–æ–≤."""
    anomalies = enhanced_explainer.analyze_anomalies(transaction, result)
    return enhanced_explainer.generate_recommendations(transaction, result, anomalies, language)

def save_transaction_feedback(transaction: Dict[str, Any], result: Dict[str, Any], 
                            feedback: bool):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –ø–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏."""
    enhanced_explainer.save_case_to_history(transaction, result, feedback)
